{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19bf0c32-abf2-4170-8b46-93288e4fc514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import multiprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b868704-6b23-4a24-84a6-fe4077833f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores_avail = max(1, multiprocessing.cpu_count() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2993eeb5-c0e8-4d4a-a1e2-72ff2042e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../experiments/configs/pitchfork_cls/main.yaml\", 'r') as f:\n",
    "    main_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714dcbe9-12ca-468f-96d4-231667e559a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_checkpoint = main_config[\"dataset_checkpoint\"]\n",
    "dataset_checkpoint_revision = main_config[\"dataset_checkpoint_revision\"]\n",
    "model_checkpoint = main_config[\"model_checkpoint\"]\n",
    "model_checkpoint_revision = main_config[\"model_checkpoint_revision\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d42f506-1222-4a62-bba7-7717ceb99f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = AutoModel.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    revision=model_checkpoint_revision\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    revision=model_checkpoint_revision\n",
    ")\n",
    "\n",
    "datasets = load_from_disk(\"../data/pitchfork/dataset_dbr/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61e5339d-c556-45e5-b547-6916170f6fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keeper_cols = [\"artist\", \"album\", \"year_released\", \"rating\", \"input_ids\", \"attention_mask\"]\n",
    "drop_cols = set(datasets[\"train\"].column_names).difference(set(keeper_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "993f416c-d209-47e3-a701-f33082f1857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = (\n",
    "    datasets\n",
    "        .map(lambda examples: tokenizer(examples[\"review\"], padding=True, truncation=True), batched=True, num_proc=num_cores_avail)\n",
    "        .remove_columns(drop_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2d26608-f5da-4be4-bfa4-f8c384ed2fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_reviews(batch):\n",
    "    # Extract input_ids and labels from the batch\n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    attention_masks = [item['attention_mask'] for item in batch]\n",
    "    ratings = [item['rating'] for item in batch]\n",
    "\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "    ratings = torch.tensor(ratings)\n",
    "\n",
    "    return input_ids, attention_masks, ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2923b42-52fb-46e5-a161-e119fb0c0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRegressor(nn.Module):\n",
    "    def __init__(self, embedder, embed_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialize the encoder (e.g., DistilBERT, BERT, etc.)\n",
    "        self.embedder = embedder\n",
    "        \n",
    "        # Regression head\n",
    "        self.regression_head = nn.Linear(embed_dim, output_dim)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Forward pass through encoder\n",
    "        embedding = self.embedder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the [CLS] embedding\n",
    "        embedding = embedding.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Forward pass through regression head\n",
    "        yhat = self.regression_head(embedding)\n",
    "        \n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f109e655-fe2e-42a9-bb6f-c5c84a0fb80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = DataLoader(tokenized_datasets[\"validation\"], batch_size=8, collate_fn=collate_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "237a4b57-7289-4ec1-b162-353b43bc18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(valid_dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc3163d8-bb42-48c6-9efd-860d54efa9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_masks, ratings = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0c21d960-ba54-467e-9661-074dbd9b31b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 27166, 13146,  ...,   112,   187,   102],\n",
       "        [  101, 10657,   117,  ..., 13028,   112,   102],\n",
       "        [  101,   107, 11065,  ..., 10111, 18850,   102],\n",
       "        ...,\n",
       "        [  101, 14178,   152,  ...,   169, 31293,   102],\n",
       "        [  101, 10117, 10992,  ...,   187, 17038,   102],\n",
       "        [  101, 11984, 72920,  ..., 51555, 44667,   102]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00ff2497-7fe5-4421-91dc-883cd236ea83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea3f7f87-1f08-4f9f-b8a3-803786c0c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextRegressor(\n",
    "    embedding_model,\n",
    "    embed_dim=embedding_model.config.dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e8222d2-9f1b-445d-a042-9d375aa2dbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextRegressor(\n",
       "  (embedder): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (regression_head): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88c9ffed-e6e4-496a-9db3-0718f251c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    yhat = model.forward(input_ids=input_ids, attention_mask=attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ecb4c4e-0f47-4f82-abda-922382a942ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0733],\n",
       "        [0.0557],\n",
       "        [0.0485],\n",
       "        [0.0741],\n",
       "        [0.0602],\n",
       "        [0.0733],\n",
       "        [0.0727],\n",
       "        [0.0574]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
