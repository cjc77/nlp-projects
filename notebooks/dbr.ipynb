{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19bf0c32-abf2-4170-8b46-93288e4fc514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import multiprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lightning.pytorch as pl\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from lightning.pytorch.callbacks import RichProgressBar\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b868704-6b23-4a24-84a6-fe4077833f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores_avail = max(1, multiprocessing.cpu_count() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2993eeb5-c0e8-4d4a-a1e2-72ff2042e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../experiments/configs/pitchfork_cls/main.yaml\", 'r') as f:\n",
    "    main_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "714dcbe9-12ca-468f-96d4-231667e559a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_checkpoint = main_config[\"dataset_checkpoint\"]\n",
    "dataset_checkpoint_revision = main_config[\"dataset_checkpoint_revision\"]\n",
    "model_checkpoint = main_config[\"model_checkpoint\"]\n",
    "model_checkpoint_revision = main_config[\"model_checkpoint_revision\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d42f506-1222-4a62-bba7-7717ceb99f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = AutoModel.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    revision=model_checkpoint_revision\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    revision=model_checkpoint_revision\n",
    ")\n",
    "\n",
    "datasets = load_from_disk(\"../data/pitchfork/dataset_dbr/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61e5339d-c556-45e5-b547-6916170f6fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keeper_cols = [\"artist\", \"album\", \"year_released\", \"rating\", \"input_ids\", \"attention_mask\"]\n",
    "drop_cols = set(datasets[\"train\"].column_names).difference(set(keeper_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "993f416c-d209-47e3-a701-f33082f1857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = (\n",
    "    datasets\n",
    "        .map(lambda examples: tokenizer(examples[\"review\"], padding=True, truncation=True), batched=True, num_proc=num_cores_avail)\n",
    "        .remove_columns(drop_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d26608-f5da-4be4-bfa4-f8c384ed2fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_reviews(batch):\n",
    "    # Extract input_ids and labels from the batch\n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    attention_masks = [item['attention_mask'] for item in batch]\n",
    "    ratings = [item['rating'] for item in batch]\n",
    "\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "    ratings = torch.tensor(ratings)\n",
    "\n",
    "    return input_ids, attention_masks, ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2923b42-52fb-46e5-a161-e119fb0c0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRegressor(nn.Module):\n",
    "    def __init__(self, embedder, embed_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initialize the encoder (e.g., DistilBERT, BERT, etc.)\n",
    "        self.embedder = embedder\n",
    "        \n",
    "        # Regression head\n",
    "        self.regression_head = nn.Linear(embed_dim, output_dim)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Forward pass through encoder\n",
    "        embedding = self.embedder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the [CLS] embedding\n",
    "        embedding = embedding.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Forward pass through regression head\n",
    "        yhat = self.regression_head(embedding)\n",
    "        \n",
    "        return yhat\n",
    "\n",
    "\n",
    "class LitTextRegressor(pl.LightningModule):\n",
    "    def __init__(self, text_regressor):\n",
    "        super().__init__()\n",
    "        self.text_regressor = text_regressor\n",
    "        # Loss\n",
    "        self.criterion = F.mse_loss\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        yhat = self.text_regressor(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return yhat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, ratings = batch\n",
    "        yhat = self.text_regressor(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        loss = self.criterion(yhat, ratings.unsqueeze(1))\n",
    "        self.log(\"avg_train_loss\", loss, on_epoch=True, on_step=False, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, ratings = batch\n",
    "        yhat = self.text_regressor(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        loss = self.criterion(yhat, ratings.unsqueeze(1))\n",
    "        self.log(\"avg_val_loss\", loss, on_epoch=True, on_step=False, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        no_wd_parameters = [\"word_embeddings\", \"position_embeddings\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in self.text_regressor.named_parameters() if any(excl in n for excl in no_wd_parameters)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in self.text_regressor.named_parameters() if all(excl not in n for excl in no_wd_parameters)],\n",
    "                \"weight_decay\": 0.01,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=1e-3)\n",
    "        return optimizer\n",
    "        \n",
    "    def freeze_pretrained_model(self):\n",
    "        # TODO: re-build optimizers after freezing/un-freezing parameters\n",
    "        for param in self.text_regressor.embedder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze_pretrained_model(self):\n",
    "        # TODO: re-build optimizers after freezing/un-freezing parameters\n",
    "        for param in self.text_regressor.embedder.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "749908e3-02d6-4aa8-9834-5379af5959ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "accelerator = \"gpu\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f109e655-fe2e-42a9-bb6f-c5c84a0fb80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_datasets[\"train\"], batch_size=batch_size, collate_fn=collate_reviews, shuffle=True)\n",
    "valid_dataloader = DataLoader(tokenized_datasets[\"validation\"], batch_size=batch_size, collate_fn=collate_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "237a4b57-7289-4ec1-b162-353b43bc18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, batch in enumerate(valid_dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc3163d8-bb42-48c6-9efd-860d54efa9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_masks, ratings = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c21d960-ba54-467e-9661-074dbd9b31b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 27166, 13146,  ...,   112,   187,   102],\n",
       "        [  101, 10657,   117,  ..., 13028,   112,   102],\n",
       "        [  101,   107, 11065,  ..., 10111, 18850,   102],\n",
       "        ...,\n",
       "        [  101, 14600, 21213,  ..., 12592, 33944,   102],\n",
       "        [  101, 12242, 10151,  ..., 56445,   119,   102],\n",
       "        [  101, 12613, 10105,  ..., 92153, 10146,   102]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00ff2497-7fe5-4421-91dc-883cd236ea83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea3f7f87-1f08-4f9f-b8a3-803786c0c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_model = TextRegressor(\n",
    "    embedding_model,\n",
    "    embed_dim=embedding_model.config.dim\n",
    ")\n",
    "lit_model = LitTextRegressor(tr_model)\n",
    "# TODO: fine-tune, then un-freeze\n",
    "lit_model.freeze_pretrained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88c9ffed-e6e4-496a-9db3-0718f251c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    lit_model.eval()\n",
    "    yhat = lit_model(input_ids=input_ids, attention_mask=attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13f80ce5-0fcf-4704-b35a-6ef5d423a0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carcook/anaconda3/envs/nlp-projects-env/lib/python3.10/site-packages/lightning/fabric/connector.py:554: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "  rank_zero_warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "callbacks = [RichProgressBar()]\n",
    "loggers = [CSVLogger(\".\", name=\"lightning_logs\"), TensorBoardLogger(\".\", name=\"tb_logs\")]\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=epochs,\n",
    "    accelerator=accelerator,\n",
    "    callbacks=callbacks,\n",
    "    precision=16,\n",
    "    logger=loggers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8da17839-011e-478c-9ecd-9bfb3ea22269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name           </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type          </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ text_regressor │ TextRegressor │  134 M │\n",
       "└───┴────────────────┴───────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName          \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType         \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ text_regressor │ TextRegressor │  134 M │\n",
       "└───┴────────────────┴───────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 769                                                                                              \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 134 M                                                                                        \n",
       "<span style=\"font-weight: bold\">Total params</span>: 134 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 538                                                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 769                                                                                              \n",
       "\u001b[1mNon-trainable params\u001b[0m: 134 M                                                                                        \n",
       "\u001b[1mTotal params\u001b[0m: 134 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 538                                                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be40332ebe346589d4660d7514472e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/carcook/anaconda3/envs/nlp-projects-env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/carcook/anaconda3/envs/nlp-projects-env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a \n",
       "bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/carcook/anaconda3/envs/nlp-projects-env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be \n",
       "a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/carcook/anaconda3/envs/nlp-projects-env/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/dat\n",
       "a_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be \n",
       "a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on \n",
       "this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model=lit_model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=valid_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278f34ab-4c43-4647-9107-91abaa5e2936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
