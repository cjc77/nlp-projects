{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12182cd0-c783-4dd2-8c16-de0ac6157952",
   "metadata": {},
   "source": [
    "[Next: Data Exploration >>](02_data_explore.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf280d1f-e575-423c-bea4-efb9962510dd",
   "metadata": {},
   "source": [
    "# Initial Dataset Preparation\n",
    "\n",
    "In this notebook, we will take a look at preparation of our root dataset. To view the next notebook in the sequence, use the navigation link above, or at the bottom of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325a3990-4dc5-4aae-b188-28dbb2951035",
   "metadata": {},
   "source": [
    "First, let's import the libraries that will be required for this notebook.\n",
    "\n",
    "Note that `myutilpy` is a custom package that has been created for this repo. It contains code that will be helpful for this sequence of notebooks. In this notebook, we import the `myutilpy.data_processing` module as `dprep` and utilize its utility functions. All of the source code is available in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c860716b-f303-485f-b4b5-03bb45649231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Custom package for this project\n",
    "import myutilpy.data_processing as dprep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b684bb-e257-4a4a-ba61-8490602036a1",
   "metadata": {},
   "source": [
    "## Configurations\n",
    "\n",
    "Next, letâ€™s do some setup. We will load the associated configurations for the desired experiment.\n",
    "\n",
    "For this sequence of notebooks, we will be fine-tuning a [`MiniLM-L6`](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) model. This model generates embeddings that capture information about passages of text, and can be used for various NLP tasks. This model is much lighter-weight (i.e., has fewer parameters) than other transformer models well-suited to the same task, but still delivers good quality performance. A helpful comparison of model architecture performance can be found [here](https://www.sbert.net/docs/pretrained_models.html). This comparison was created by the authors of this (and several other) models uploaded to the [Hugging Face](https://huggingface.co/) model repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b266c8d-cab5-4466-85b0-2019f5f6e3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_id = \"mlml6_rate_pred_clsp\"\n",
    "num_cores_avail = max(1, multiprocessing.cpu_count() - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7aa92a-993c-4ab5-adbe-ac689e67fa4d",
   "metadata": {},
   "source": [
    "Configuration settings are stored in `.yaml` files in the `experiments/configs/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65745be1-2ede-4302-931b-9b07732d1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../experiments/configs/{config_id}/main.yaml\", 'r') as f:\n",
    "    main_config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e75cb4-cd16-444f-9a55-e5c90bc417b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_checkpoint = main_config[\"dataset_checkpoint\"]\n",
    "dataset_checkpoint_revision = main_config[\"dataset_checkpoint_revision\"]\n",
    "pt_model_checkpoint = main_config[\"pt_model_checkpoint\"]\n",
    "pt_model_checkpoint_revision = main_config[\"pt_model_checkpoint_revision\"]\n",
    "dataset_id = main_config[\"dataset_id\"]\n",
    "data_seed = main_config[\"data_seed\"]\n",
    "\n",
    "root_dataset_dir = f\"../data/pitchfork/{dataset_id}\"\n",
    "raw_data_cache_dir = f\"../data/pitchfork/raw/cache\"\n",
    "Path(raw_data_cache_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(root_dataset_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6da5c4-c48d-4b18-bdea-996dec8f5db6",
   "metadata": {},
   "source": [
    "## Tokenizer and dataset loading\n",
    "\n",
    "Now, we will load the tokenizer associated with our model of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bd6ad7b-1852-4435-b069-883bef363648",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pt_model_checkpoint,\n",
    "    revision=pt_model_checkpoint_revision\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93b89e2-d417-40ce-a85b-a7c182414371",
   "metadata": {},
   "source": [
    "Let's also download the dataset that we will be using for this project. The dataset consists of [Pitchfork](https://pitchfork.com/) music reviews scraped from their website. A full description of the dataset can be found in the [dataset description card](https://huggingface.co/datasets/mattismegevand/pitchfork)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d287c54-85f8-42d9-bbb1-05a8c4d1c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to specify \"reviews.csv\" since it will default to album images\n",
    "raw_datasets = load_dataset(\n",
    "    dataset_checkpoint,\n",
    "    revision=dataset_checkpoint_revision,\n",
    "    data_files=[\"reviews.csv\"],\n",
    "    cache_dir=raw_data_cache_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b6d844-02f1-40bf-a89e-831e32d72ef9",
   "metadata": {},
   "source": [
    "Before moving on, let's have a quick look at the dataset summary. Notice that the data do not come pre-split. All rows (observations) are in the `\"Train\"` split by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48d4df6f-b365-4e21-ac36-bf71bc985d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['artist', 'album', 'year_released', 'rating', 'small_text', 'review', 'reviewer', 'genre', 'label', 'reviewed', 'album_art_url'],\n",
       "        num_rows: 25709\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea7f4d-efae-4e28-b60e-14ff62f5ad79",
   "metadata": {},
   "source": [
    "## Preprocess raw dataset\n",
    "\n",
    "The first major step is to clean and preprocess the raw data. We will do some exploratory analysis after this step is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "423ff026-2f45-46d7-8b12-b9bd576dbecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raw_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34daf94-b9fd-4745-a619-a6d999fbd170",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "\n",
    "The first filtration step we will do is to exclude rows where the `\"artist\"`, `\"album\"`, `\"review\"`, or `\"reviewer\"` fields are non-strings (e.g., `None`). This is because, if we decide we want to do any analysis about any of these columns, we want to make sure valid data are present in the rows of our prepared dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9c2cb93-c14f-4d24-944b-5e2456497da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f85ecafb4604c8e95e12834f652ea49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=15):   0%|          | 0/25709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The artist, album, review, and reviewer columns should be strings (e.g., should not be None)\n",
    "dataset = dataset.filter(\n",
    "    lambda examples: dprep.detect_wrong_type_batched(examples, [\"artist\", \"album\", \"review\", \"reviewer\"], str),\n",
    "    batched=True,\n",
    "    num_proc=num_cores_avail\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd21ef50-d103-484b-ba66-c1e4dc04db3a",
   "metadata": {},
   "source": [
    "We see that we filtered out a decent number of rows with this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37653f5d-bfca-407e-83f7-abe49393df52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['artist', 'album', 'year_released', 'rating', 'small_text', 'review', 'reviewer', 'genre', 'label', 'reviewed', 'album_art_url'],\n",
       "    num_rows: 23034\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0dbb14-e014-4523-88da-ac3aa19f4cd2",
   "metadata": {},
   "source": [
    "### Duplicates\n",
    "\n",
    "One common issue with datasets scraped from the web is that, along with missing values, they may contain duplicate rows. Fortunately, our dataset is small enough that we can use built-in `pandas` functionality to drop duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad307e91-0c30-463c-a38b-ba40323a2064",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(\n",
    "    dataset.to_pandas().drop_duplicates().reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158bb838-c9a1-43f3-a6f0-baa3fddc2a57",
   "metadata": {},
   "source": [
    "We see that several rows were dropped when checking for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a16de2d8-a39e-44f1-bc10-c1b1e420b37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['artist', 'album', 'year_released', 'rating', 'small_text', 'review', 'reviewer', 'genre', 'label', 'reviewed', 'album_art_url'],\n",
       "    num_rows: 22063\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ec6514-1f45-404b-9721-bcbd863c4c6d",
   "metadata": {},
   "source": [
    "### Unknown tokens\n",
    "\n",
    "Next, we will attempt to minimize the number of \"unknown\" tokens that find their way into our dataset. The `MiniLM-L6` model uses a tokenizer that has an `[UNK]` token for words/letters that did not appear in the training dataset. This is not a huge issue in general, but can degrade performance if it occurs frequently. For this reason, we will attempt to replace common characters in our data that map to the `[UNK]` token. For example, we will replace the 'â€œ' character with '\"' and the 'â™¡' character with 'heart'. This will help prevent easily avoidable degradation of performance. For a full list of replaced characters (or sequences of characters), see [`myutilpy/data_preprocessing.py`](../myutilpy/myutilpy/data_processing.py) in the project source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "871481a9-7045-42dc-8831-f07c97827c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5312330879224ba785254dac2b7334c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/22063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "blacklist_pattern = dprep.get_blacklist_pattern(dataset_id)\n",
    "\n",
    "# Replace known \"unk\" tokens\n",
    "dataset = dataset.map(\n",
    "    lambda examples: dprep.replace_known_unk_tokens_batched(examples, [\"artist\", \"album\", \"review\", \"reviewer\"], blacklist_pattern),\n",
    "    batched=True,\n",
    "    num_proc=num_cores_avail\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac5ac41-2e69-4adf-8da2-312744b16562",
   "metadata": {},
   "source": [
    "Let's check to see how many rows still contain unknown tokens in the `\"review\"` column. Note that many of the `\"review\"` entries exceed the maximum model sequence length. More on this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd5a164c-f9bf-41d4-a1e4-167ac1956114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fc2c16b1c6476e978e769c94bac02a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=15):   0%|          | 0/22063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (924 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (852 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (586 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (902 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "dataset_leftover = dataset.filter(\n",
    "    lambda examples: dprep.detect_unk_batched(examples, [\"review\"], tokenizer),\n",
    "    batched=True,\n",
    "    num_proc=num_cores_avail\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb06d8e-3755-466e-878c-d8b49871b59b",
   "metadata": {},
   "source": [
    "Fortunately, there do not appear to be many left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb0ac968-909b-4db7-9b1a-6a8d1c83b855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['artist', 'album', 'year_released', 'rating', 'small_text', 'review', 'reviewer', 'genre', 'label', 'reviewed', 'album_art_url'],\n",
       "    num_rows: 48\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_leftover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817e0b34-a836-4355-900e-6a08fd175333",
   "metadata": {},
   "source": [
    "#### Closer look\n",
    "Let's take a closer look at which tokens are still mapped to `[UNK]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8de87bfc-da97-4063-9212-abb48c7d0303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (773 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "unk_tokens = set()\n",
    "for i in range(len(dataset_leftover)):\n",
    "    text = dataset_leftover[i][\"review\"]\n",
    "    inputs = tokenizer(text, return_offsets_mapping=True)\n",
    "    ids = inputs.input_ids\n",
    "    offsets = inputs.offset_mapping\n",
    "    \n",
    "    for j, id in enumerate(ids):\n",
    "        if id == tokenizer.unk_token_id:\n",
    "            unk_tokens.add(text[offsets[j][0]: offsets[j][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fed23755-a789-4170-ad22-4ec1f96951fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è€… emphaticÂ¸ âŒ˜v å…ˆ ç‡• éŸ³ æœƒ å®¢ é‡ â“‡ æˆ° âœ“ 14â„ƒ æ„š è’¸ èˆ‡ å¥ è›° Â¯ â™ˆ ï½¡ ç»¿ â™‘ åˆ¶ å¿µ 0â„ƒ å¡ é¬¼ è±¡ å‰£ â€½ å…° å¸‚ çŸ® ì˜›ë‚ ì´ì•¼ê¸° á‹˜áˆ‹áˆˆáˆ ç–Š â€ å†¥ æ•— ØŸ â—• é–ƒ â˜½ ä¾† ä¹ å¸Œ ã‚½ã‚™ãƒƒãƒˆ Ë‚strangerËƒ å» â˜• 36â„ƒ è©© ç‰ æƒŠ 17â„ƒ æƒ³ éœŠ Éªá´á´˜á´€á´„á´›21 éš  æµ´ å» éˆ å¹½ ë°•í˜œì§„ æ›œ è‹‘ YTIâ…ƒAÆĞ¯ dâ€‹á´‰â€‹lÉŸ 10â„ƒ ã†ãŸã®ãã—ã‚ƒ ç‰© å‚ ä¹± å‰ å° è¦³ è§‚ æ®º æ‰€ æŒ‡ å¤¢ æ³¢ å‘¼ ç¸¦ ç•Œ â–¡ ê°œê¿ˆ ç¯€ ç‹— å…± æ€• è½‰ ä¸ƒ ç¸ é ğŸ’¯ ÆšI é§­ åª Æ¨bnÆ ä½› å®³ èŒ¶ å¸ âŒ˜\n"
     ]
    }
   ],
   "source": [
    "print(*unk_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a952642d-fb2f-4fd7-81f7-c679621edcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lucy Liyou', 'Mark Barrott', 'Tzusing', 'Lucinda Chua', 'otay:onii', 'Two Shell', 'Bill Callahan', 'Sam Gendel', 'Willow', 'deathâ€™s dynamic shroud', '4s4ki', 'Tatsuro Yamashita', 'Two Shell', 'Whatever the Weather', 'Pan Daijing', 'JPEGMAFIA', 'Yikii', 'ë°•í˜œì§„ Park Hye Jin', 'Pan Daijing', 'Jusell, Prymek, Sage, Shiroishi', 'Rian Treanor', 'ë°•í˜œì§„ Park Hye Jin', 'Okkyung Lee', 'Gong Gong Gong å·¥å·¥å·¥', 'Fire-Toolz', 'Brian Eno', 'BTS', 'HARAM', 'RRUCCULLA', 'George Clanton', 'Fire-Toolz', 'Meuko! Meuko!', 'BTS', 'Mukqs', 'Guided by Voices', 'Varg2TM', 'Grandaddy', 'Toyomu', 'Mikael Seifu', 'Especia', 'Creepoid', 'Kosmo Kat', 'TV on the Radio', 'Lee', 'Ryan Hemsworth', 'Javelin', 'The Soft Moon', 'Pit Er Pat']\n"
     ]
    }
   ],
   "source": [
    "print(dataset_leftover[\"artist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31edea1b-58b8-4074-8635-f4789ee09175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dog Dreams (ê°œê¿ˆ)', 'JÅhatsu (è’¸ç™º)', 'ç»¿å¸½ Green Hat', 'YIAN', 'å¤¢ä¹‹é§­å®¢ Dream Hacker', 'lil spirits', 'YTIâ…ƒAÆĞ¯', 'Blueblue', '<CopingMechanism>', 'Darklife', 'Killer in Neverland', 'Softly', 'Icons EP', 'Whatever the Weather', 'Tissues', 'LP!', 'Crimson Poem', 'Before I Die', 'Jade ç‰è§‚éŸ³', 'Fuubutsushi (é¢¨ç‰©è©©)', 'File Under UK Metaplasm', 'How can I', 'Yeo\\u200b-\\u200bNeun', 'Phantom Rhythm å¹½éˆç¯€å¥ (å¹½éœŠãƒªã‚ºãƒ )', 'Field Whispers (Into the Crystal Palace)', 'Apollo: Atmospheres & Soundtracks - Extended Edition', 'MAP OF THE SOUL : PERSONA', 'ÙˆÙŠÙ† ÙƒÙ†ÙŠØª Ø¨ÙŠ 11\\u200b/\\u200b9ØŸ? â€œWhere Were You on 9\\u200b/\\u200b11\\u200b?\\u200bâ€ EP', 'SHuSH', 'Slide', 'Skinless X-1', 'é¬¼å³¶ Ghost Island EP', 'Love Yourself è½‰ â€˜Tearâ€™', 'èµ·ãä¸Šã‹ã‚™ã‚Š', 'August by Cake', 'Nordic Flora Series Pt. 3: Gore-Tex City', 'Last Place', 'å°è±¡III : ãªã‚“ã¨ãªãã€ãƒ‘ãƒ–ãƒ­ (Imagining â€œThe Life of Pabloâ€)', 'Zelalem', 'Carta', 'Cemetery Highrise Slum', 'Square EP', 'Seeds', 'TANHÃ‚', 'Still Awake EP', 'Hi Beams', 'Zeros', 'High Time']\n"
     ]
    }
   ],
   "source": [
    "print(dataset_leftover[\"album\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae64807-4911-4fa1-92ea-a0eab45cca05",
   "metadata": {},
   "source": [
    "It appears that many of the unknown characters are within the `\"artist\"` or `\"album\"` name, and these names will obviously nearly always appear within the body of the review. Fortunately, though, we are not directly embedding artist or album names (aside from their occurrences within the `\"review\"` text) when performing prediction in our model. For this reason, we can move on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30022239-2c13-4b21-860f-7341cde20555",
   "metadata": {},
   "source": [
    "## Analysis prep\n",
    "\n",
    "Let's prepare a summary of our dataset that will be useful for conducting some exploratory analysis before we fit our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d065eea-933e-4aee-a148-cb2b4d844cb8",
   "metadata": {},
   "source": [
    "### Token counts\n",
    "\n",
    "When we do exploratory analysis of data characteristics and modeling results, we may want to know the number of tokens that appeared in each review. Let's add that column to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a4f4bc1-ea1c-46cf-a094-06631fb5cc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48433f25be754b51a0ac90073e45aca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=15):   0%|          | 0/22063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda examples: dprep.get_n_tokens_batched(examples, \"review\", tokenizer),\n",
    "    batched=True,\n",
    "    num_proc=num_cores_avail\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec5dd5-c955-43ba-a00e-ecb66a0f39d9",
   "metadata": {},
   "source": [
    "### Collect summary features into dataframe\n",
    "\n",
    "Let's compile the important columns for exploratory analysis into a `summary_dataset`, and convert it to a dataframe for subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8009fd83-33c3-40b6-9167-5c21928ed4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_dataset_df = (\n",
    "    dataset\n",
    "        .remove_columns([\"year_released\", \"small_text\", \"album_art_url\", \"review\"])\n",
    "        .to_pandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b659b9-77b7-40df-9c83-07946117f7eb",
   "metadata": {},
   "source": [
    "## Split data\n",
    "\n",
    "Finally, we want to prepare our data for model fitting by breaking it up into train, validation, and test sets.\n",
    "\n",
    "Let's go with a 70-15-15 train-validation-test split.\r\n",
    " - 70% for training is solid for fine-tuning.\r\n",
    " - 15% each for val and test for reliable overfitting estimates and testing.\r\n",
    " - A 60-20-20 split would be better for a smaller dataset or a simpler model.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13b3846e-55d2-42a7-85cc-49a73d97ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split the dataset into \"train\" and \"test\" where \"test\" will be used to\n",
    "# build the true \"validation\" and \"test\" splits\n",
    "datasets = dataset.train_test_split(test_size=0.3, seed=data_seed)\n",
    "\n",
    "# Now, split the temp dataset into validation and test sets\n",
    "datasets_val_test = datasets.pop(\"test\").train_test_split(test_size=0.5)\n",
    "datasets[\"validation\"] = datasets_val_test.pop(\"train\")\n",
    "datasets[\"test\"] = datasets_val_test.pop(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8824f3-acd9-4d96-9405-b0a5d2137493",
   "metadata": {},
   "source": [
    "Let's look at the outputs of splitting our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edf7ec86-7380-4bbd-82d1-3ba8894fbdd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['artist', 'album', 'year_released', 'rating', 'small_text', 'review', 'reviewer', 'genre', 'label', 'reviewed', 'album_art_url', 'review_n_tokens'],\n",
       "        num_rows: 15444\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['artist', 'album', 'year_released', 'rating', 'small_text', 'review', 'reviewer', 'genre', 'label', 'reviewed', 'album_art_url', 'review_n_tokens'],\n",
       "        num_rows: 3309\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['artist', 'album', 'year_released', 'rating', 'small_text', 'review', 'reviewer', 'genre', 'label', 'reviewed', 'album_art_url', 'review_n_tokens'],\n",
       "        num_rows: 3310\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9c45f7-ae77-4b6a-83ab-f0f1f718fdfd",
   "metadata": {},
   "source": [
    "## Save out data\n",
    "\n",
    "Finally, let's save out our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e35c5363-5f6d-4042-889a-92f2f5b29b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1890792a7da46bc838f5408cc850630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/15444 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329246da26ff46abb7aa0701db061177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3309 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf833fd0b067484082e593f1a65a764a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3310 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_dataset_df.to_csv(f\"{root_dataset_dir}/summary_df.csv\", index=False)\n",
    "datasets.save_to_disk(f\"{root_dataset_dir}/dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d34919-f2ae-4041-a076-339630f34d0a",
   "metadata": {},
   "source": [
    "[Next: Data Exploration >>](02_data_explore.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
